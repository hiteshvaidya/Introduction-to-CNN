{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various applications of CNN in ML\n",
    "\n",
    "\n",
    "\n",
    "## Timeline\n",
    "- What is intelligence and the general Buzzwords\n",
    "- What is the ultimate aim\n",
    "- What is a neural network\n",
    "- What are different types of neural networks and when to use them\n",
    "- Convolutional neural networks\n",
    "- Different applications of CNNs\n",
    "- Is CNN the ultimate solution?\n",
    "- Some modern methods\n",
    "\n",
    "\n",
    "## What is intelligence and the general Buzzwords\n",
    "![](images/1.png)\n",
    "\n",
    "\n",
    "## What is the ultimate aim?\n",
    "![](images/2.png)<br>\n",
    "<center><font size=\"5\">**Artificial General Intelligence or Strong AI or Human Level AI**</font></center>\n",
    "<br><br><br>\n",
    "\n",
    "\n",
    "<font size=\"5\">**Neural Networks, the holly grail**</font>\n",
    "![](images/4.png)<br>\n",
    "<center><font size=\"4\">**Function Approximation**</font></center>\n",
    "<br><br>\n",
    "![](images/3.png)\n",
    "\n",
    "\n",
    "### Which one to choose?\n",
    "Feed forward Neural Networks &nbsp; &rarr; &nbsp; Deterministic approach<br><br>\n",
    "Recurrent Neural Networks &nbsp; &rarr; &nbsp; Time dependent data<br><br>\n",
    "Convolutional Neural Networks &nbsp; &rarr; &nbsp; Vision tasks<br><br>\n",
    "\n",
    "\n",
    "## Convolutional Neural Networks\n",
    "![](images/5.png)\n",
    "CNNs are biologically-inspired models inspired by research by D. H. Hubel and T. N. Wiesel. They proposed an explanation for the way in which mammals visually perceive the world around them using a layered architecture of neurons in the brain, and this in turn inspired engineers to attempt to develop similar pattern recognition mechanisms in computer vision.<br>\n",
    "The architecture of deep convolutional neural networks was inspired by the ideas mentioned above\n",
    "\n",
    "- local connections\n",
    "- layering\n",
    "- spatial invariance (shifting the input signal results in an equally shifted output signal. , most of us are able to recognize specific faces under a variety of conditions because we learn abstraction These abstractions are thus invariant to size, contrast, rotation, orientation\n",
    "\n",
    "### Step 1 - Prepare a dataset of images\n",
    "![](images/6.png)\n",
    "- The image is matrix of RGB colours. Each of these colour channels have a range [0, 255] and such values for all three channels are considered while doing any operation. Thus the image in it’s entirety, constitutes a 3-dimensional structure called the Input Volume (255x255x3). \n",
    "\n",
    "### Step 2 - Convolution \n",
    "\n",
    "![alt text](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/more_images/Convolution_schematic.gif \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](http://xrds.acm.org/blog/wp-content/uploads/2016/06/Figure_2.png \"Logo Title Text 1\")\n",
    "\n",
    "- A convolution is an orderly procedure where two sources of information are intertwined.\n",
    "\n",
    "- A kernel (also called a filter) is a smaller-sized matrix in comparison to the input dimensions of the image, that consists of real valued entries.\n",
    "\n",
    "- Kernels are then convolved with the input volume to obtain so-called ‘activation maps’ (also called feature maps).  \n",
    "- Activation maps indicate ‘activated’ regions, i.e. regions where features specific to the kernel have been detected in the input. \n",
    "\n",
    "- The real values of the kernel matrix change with each learning iteration over the training set, indicating that the network is learning to identify which regions are of significance for extracting features from the data.\n",
    "\n",
    "- We compute the dot product between the kernel and the input matrix. -The convolved value obtained by summing the resultant terms from the dot product forms a single entry in the activation matrix. \n",
    "\n",
    "- The patch selection is then slided (towards the right, or downwards when the boundary of the matrix is reached) by a certain amount called the ‘stride’ value, and the process is repeated till the entire input image has been processed. - The process is carried out for all colour channels.\n",
    "\n",
    "- instead of connecting each neuron to all possible pixels, we specify a 2 dimensional region called the ‘receptive field[14]’ (say of size 5×5 units) extending to the entire depth of the input (5x5x3 for a 3 colour channel input), within which the encompassed pixels are fully connected to the neural network’s input layer. It’s over these small regions that the network layer cross-sections (each consisting of several neurons (called ‘depth columns’)) operate and produce the activation map. (reduces computational complexity)\n",
    "\n",
    "![alt text](http://i.imgur.com/g4hRI6Z.png \"Logo Title Text 1\")\n",
    "![alt text](http://i.imgur.com/tpQvMps.jpg \"Logo Title Text 1\")\n",
    "![alt text](http://i.imgur.com/oyXkhHi.jpg \"Logo Title Text 1\")\n",
    "![alt text](http://xrds.acm.org/blog/wp-content/uploads/2016/06/Figure_5.png \"Logo Title Text 1\")\n",
    "\n",
    "Great resource on description of  convolution (discrete vs continous)  & the fourier transform\n",
    "\n",
    "http://timdettmers.com/2015/03/26/convolution-deep-learning/\n",
    "\n",
    "\n",
    "###  Step 3 - Pooling\n",
    "![alt text](http://xrds.acm.org/blog/wp-content/uploads/2016/06/Figure_6.png \"Logo Title Text 1\")\n",
    "\n",
    "- Pooling reducing the spatial dimensions (Width x Height) of the Input Volume for the next Convolutional Layer. It does not affect the depth dimension of the Volume.  \n",
    "- The transformation is either performed by taking the maximum value from the values observable in the window (called ‘max pooling’), or by taking the average of the values. Max pooling has been favoured over others due to its better performance characteristics.\n",
    "- also called downsampling\n",
    "\n",
    "###  Step 4 - Normalization (ReLU in our case)\n",
    "\n",
    "![alt text](http://xrds.acm.org/blog/wp-content/uploads/2016/06/CodeCogsEqn-3.png \"Logo Title Text 1\")\n",
    "\n",
    "Normalization (keep the math from breaking by turning all negative numbers to 0)  (RELU) a stack of images becomes a stack of images with no negative values. \n",
    "\n",
    "Repeat Steps 2-4 several times. More, smaller images (feature maps created at every layer)\n",
    "\n",
    "### Step 5 - Regularization \n",
    "\n",
    "- Dropout forces an artificial neural network to learn multiple independent representations of the same data by alternately randomly disabling neurons in the learning phase.\n",
    "- Dropout is a vital feature in almost every state-of-the-art neural network implementation.\n",
    "- To perform dropout on a layer, you randomly set some of the layer's values to 0 during forward propagation.\n",
    "\n",
    "See [this](http://iamtrask.github.io/2015/07/28/dropout/)\n",
    "\n",
    "![alt text](https://i.stack.imgur.com/CewjH.png \"Logo Title Text 1\")\n",
    "\n",
    "###  Step 6 - Probability Conversion\n",
    "\n",
    "At the very end of our network (the tail), we'll apply a softmax function to convert the outputs to probability values for each class. \n",
    "\n",
    "![alt text](https://1.bp.blogspot.com/-FHDU505euic/Vs1iJjXHG0I/AAAAAAABVKg/x4g0FHuz7_A/s1600/softmax.JPG \"Logo Title Text 1\")\n",
    "\n",
    "\n",
    "###  Step 7 - Choose most likely label (max probability value) \n",
    "\n",
    "argmax(softmax_outputs)\n",
    "\n",
    "These 7 steps are one forward pass through the network.\n",
    "\n",
    "## So how do we learn the magic numbers? \n",
    "\n",
    "- We can learn features and weight values through backpropagation\n",
    "\n",
    "![alt text](http://www.robots.ox.ac.uk/~vgg/practicals/cnn/images/cover.png \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](https://image.slidesharecdn.com/cnn-toupload-final-151117124948-lva1-app6892/95/convolutional-neural-networks-cnn-52-638.jpg?cb=1455889178 \"Logo Title Text 1\")\n",
    "\n",
    "The other hyperparameters are set by humans and they are an active field of research (finding the optimal ones)\n",
    "\n",
    "i.e -  number of neurons, number of features, size of features, poooling window size, window stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good examples\n",
    "\n",
    "<ol>\n",
    "**<li> Image Classifier**\n",
    "![](images/8.jpeg)\n",
    "    <br><br>\n",
    "<li> **Object Detection**\n",
    "![](images/7.jpeg)\n",
    "<br><br>\n",
    "\n",
    "**<li> Image Captioning**\n",
    "    ![](images/10.jpg)\n",
    "<br><br>\n",
    "\n",
    "**<li> CNN with Generative Adversarial Networks**\n",
    "    ![](images/11.png)\n",
    "<br><br>\n",
    "\n",
    "**<li> Deep Fakes**\n",
    "  ![](images/12.JPG)\n",
    "    \n",
    "</ol>\n",
    "<br><br>\n",
    "\n",
    "## Is CNN the ultimate Solution?\n",
    "![](images/9.png)\n",
    "<br><br>\n",
    "**<div style=\"text-align:center\"><font size=\"5\">Capsule Network</font></div>**\n",
    "\n",
    "<br><br>\n",
    "## Some modern methods in Machine Intelligence\n",
    "### [Numenta](https://numenta.org/)\n",
    "<br>\n",
    "![](images/14.jpeg)\n",
    "<br>\n",
    "**<div style=\"text-align:center\"><font size=\"5\">Using neuroscience to form the third generation of Artificial Intelligence</font></div>**\n",
    "<br>\n",
    "![](images/13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
